{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow\n",
    "from tensorflow_core.python.keras.utils.data_utils import Sequence\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = pd.read_csv(\"life_expectancy_seperated_columns.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(dataset.head())\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       Country  Year      Status  Adult Mortality  infant deaths  Alcohol  \\\n",
      "0  Afghanistan  2015  Developing              263             62     0.01   \n",
      "1  Afghanistan  2014  Developing              271             64     0.01   \n",
      "2  Afghanistan  2013  Developing              268             66     0.01   \n",
      "3  Afghanistan  2012  Developing              272             69     0.01   \n",
      "4  Afghanistan  2011  Developing              275             71     0.01   \n",
      "\n",
      "   percentage expenditure  Hepatitis B  Measles    BMI   ...  \\\n",
      "0               71.279624           65      1154   19.1  ...   \n",
      "1               73.523582           62       492   18.6  ...   \n",
      "2               73.219243           64       430   18.1  ...   \n",
      "3               78.184215           67      2787   17.6  ...   \n",
      "4                7.097109           68      3013   17.2  ...   \n",
      "\n",
      "   Total expenditure  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
      "0               8.16           65        0.1  584.259210  33736494.0   \n",
      "1               8.18           62        0.1  612.696514    327582.0   \n",
      "2               8.13           64        0.1  631.744976  31731688.0   \n",
      "3               8.52           67        0.1  669.959000   3696958.0   \n",
      "4               7.87           68        0.1   63.537231   2978599.0   \n",
      "\n",
      "    thinness  1-19 years   thinness 5-9 years  \\\n",
      "0                   17.2                 17.3   \n",
      "1                   17.5                 17.5   \n",
      "2                   17.7                 17.7   \n",
      "3                   17.9                 18.0   \n",
      "4                   18.2                 18.2   \n",
      "\n",
      "   Income composition of resources  Schooling  Life expectancy  \n",
      "0                            0.479       10.1             65.0  \n",
      "1                            0.476       10.0             59.9  \n",
      "2                            0.470        9.9             59.9  \n",
      "3                            0.463        9.8             59.5  \n",
      "4                            0.454        9.5             59.2  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(dataset.describe())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              Year  Adult Mortality  infant deaths      Alcohol  \\\n",
      "count  2938.000000      2938.000000    2938.000000  2938.000000   \n",
      "mean   2007.518720       164.725664      30.303948     4.546875   \n",
      "std       4.613841       124.086215     117.926501     3.921946   \n",
      "min    2000.000000         1.000000       0.000000     0.010000   \n",
      "25%    2004.000000        74.000000       0.000000     1.092500   \n",
      "50%    2008.000000       144.000000       3.000000     3.755000   \n",
      "75%    2012.000000       227.000000      22.000000     7.390000   \n",
      "max    2015.000000       723.000000    1800.000000    17.870000   \n",
      "\n",
      "       percentage expenditure  Hepatitis B       Measles          BMI   \\\n",
      "count             2938.000000  2938.000000    2938.000000  2938.000000   \n",
      "mean               738.251295    83.022124    2419.592240    38.381178   \n",
      "std               1987.914858    22.996984   11467.272489    19.935375   \n",
      "min                  0.000000     1.000000       0.000000     1.000000   \n",
      "25%                  4.685343    82.000000       0.000000    19.400000   \n",
      "50%                 64.912906    92.000000      17.000000    43.500000   \n",
      "75%                441.534144    96.000000     360.250000    56.100000   \n",
      "max              19479.911610    99.000000  212183.000000    87.300000   \n",
      "\n",
      "       under-five deaths         Polio  Total expenditure  Diphtheria   \\\n",
      "count         2938.000000  2938.000000        2938.000000  2938.000000   \n",
      "mean            42.035739    82.617767           5.924098    82.393125   \n",
      "std            160.445548    23.367166           2.400770    23.655562   \n",
      "min              0.000000     3.000000           0.370000     2.000000   \n",
      "25%              0.000000    78.000000           4.370000    78.000000   \n",
      "50%              4.000000    93.000000           5.755000    93.000000   \n",
      "75%             28.000000    97.000000           7.330000    97.000000   \n",
      "max           2500.000000    99.000000          17.600000    99.000000   \n",
      "\n",
      "          HIV/AIDS            GDP    Population   thinness  1-19 years  \\\n",
      "count  2938.000000    2938.000000  2.938000e+03            2938.000000   \n",
      "mean      1.742103    6611.523863  1.023085e+07               4.821886   \n",
      "std       5.077785   13296.603449  5.402242e+07               4.397621   \n",
      "min       0.100000       1.681350  3.400000e+01               0.100000   \n",
      "25%       0.100000     580.486996  4.189172e+05               1.600000   \n",
      "50%       0.100000    1766.947595  1.386542e+06               3.300000   \n",
      "75%       0.800000    4779.405190  4.584371e+06               7.100000   \n",
      "max      50.600000  119172.741800  1.293859e+09              27.700000   \n",
      "\n",
      "        thinness 5-9 years  Income composition of resources    Schooling  \\\n",
      "count          2938.000000                      2938.000000  2938.000000   \n",
      "mean              4.852144                         0.630362    12.009837   \n",
      "std               4.485854                         0.205140     3.265139   \n",
      "min               0.100000                         0.000000     0.000000   \n",
      "25%               1.600000                         0.504250    10.300000   \n",
      "50%               3.300000                         0.677000    12.300000   \n",
      "75%               7.200000                         0.772000    14.100000   \n",
      "max              28.600000                         0.948000    20.700000   \n",
      "\n",
      "       Life expectancy  \n",
      "count      2938.000000  \n",
      "mean         69.234717  \n",
      "std           9.509115  \n",
      "min          36.300000  \n",
      "25%          63.200000  \n",
      "50%          72.100000  \n",
      "75%          75.600000  \n",
      "max          89.000000  \n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "labels = dataset.iloc[:,-1]\n",
    "features = dataset.iloc[:,0:-1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "features = pd.get_dummies(features)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size = 0.30, random_state=29)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "numerical_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "numerical_columns = numerical_features.columns\n",
    " \n",
    "ct = ColumnTransformer([(\"only numeric\", StandardScaler(), numerical_columns)], remainder='passthrough')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "features_train_scaled = ct.fit_transform(features_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "my_model = Sequential()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "input = InputLayer(input_shape = (features.shape[1], ))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "my_model.add(input)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "my_model.add(Dense(64, activation = \"relu\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "my_model.add(Dense(1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "print(my_model.summary())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 64)                13760     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 13,825\n",
      "Trainable params: 13,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "opt = Adam(learning_rate = 0.01)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "my_model.compile(loss = 'mse', metrics = ['mae'], optimizer = opt)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(features_train_scaled.shape, features_train_scaled.dtype)\n",
    "print(labels_train.shape, labels_train.dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2056, 214) float64\n",
      "(2056,) float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "features_train_scaled = pd.DataFrame(features_train_scaled)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "my_model.fit(features_train_scaled, labels_train, epochs = 50, batch_size = 1, verbose = 1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 2056 samples\n",
      "Epoch 1/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 167.9628 - mae: 6.7023\n",
      "Epoch 2/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 21.0471 - mae: 3.3260\n",
      "Epoch 3/50\n",
      "2056/2056 [==============================] - 5s 2ms/sample - loss: 16.8692 - mae: 2.9640\n",
      "Epoch 4/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 16.0759 - mae: 2.9514\n",
      "Epoch 5/50\n",
      "2056/2056 [==============================] - 5s 3ms/sample - loss: 13.0919 - mae: 2.7240\n",
      "Epoch 6/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 14.6279 - mae: 2.7582\n",
      "Epoch 7/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 11.8393 - mae: 2.4508\n",
      "Epoch 8/50\n",
      "2056/2056 [==============================] - 7s 4ms/sample - loss: 11.6524 - mae: 2.4897\n",
      "Epoch 9/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 11.3574 - mae: 2.3790\n",
      "Epoch 10/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 10.0639 - mae: 2.2885\n",
      "Epoch 11/50\n",
      "2056/2056 [==============================] - 5s 2ms/sample - loss: 9.3782 - mae: 2.1900\n",
      "Epoch 12/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 7.4238 - mae: 2.0549\n",
      "Epoch 13/50\n",
      "2056/2056 [==============================] - 12s 6ms/sample - loss: 8.3360 - mae: 2.1295\n",
      "Epoch 14/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 8.9508 - mae: 2.0735\n",
      "Epoch 15/50\n",
      "2056/2056 [==============================] - 9s 4ms/sample - loss: 7.0643 - mae: 1.9394\n",
      "Epoch 16/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 7.9673 - mae: 1.9805\n",
      "Epoch 17/50\n",
      "2056/2056 [==============================] - 9s 4ms/sample - loss: 7.9685 - mae: 1.9230\n",
      "Epoch 18/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 7.2631 - mae: 1.8770\n",
      "Epoch 19/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 5.4446 - mae: 1.7275\n",
      "Epoch 20/50\n",
      "2056/2056 [==============================] - 9s 5ms/sample - loss: 6.2897 - mae: 1.8119\n",
      "Epoch 21/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 5.1440 - mae: 1.7109\n",
      "Epoch 22/50\n",
      "2056/2056 [==============================] - 9s 5ms/sample - loss: 5.4625 - mae: 1.7060\n",
      "Epoch 23/50\n",
      "2056/2056 [==============================] - 9s 4ms/sample - loss: 6.1584 - mae: 1.6655\n",
      "Epoch 24/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 5.1591 - mae: 1.6763\n",
      "Epoch 25/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 4.7708 - mae: 1.6037\n",
      "Epoch 26/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 5.1888 - mae: 1.6353\n",
      "Epoch 27/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 4.9577 - mae: 1.5999\n",
      "Epoch 28/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 4.0484 - mae: 1.4482\n",
      "Epoch 29/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 6.0813 - mae: 1.5682\n",
      "Epoch 30/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 4.8217 - mae: 1.4851\n",
      "Epoch 31/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 4.1750 - mae: 1.4891\n",
      "Epoch 32/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 4.2446 - mae: 1.4487\n",
      "Epoch 33/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 4.1295 - mae: 1.4228\n",
      "Epoch 34/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 4.0754 - mae: 1.4386\n",
      "Epoch 35/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 3.9443 - mae: 1.4078\n",
      "Epoch 36/50\n",
      "2056/2056 [==============================] - 6s 3ms/sample - loss: 3.8825 - mae: 1.3777\n",
      "Epoch 37/50\n",
      "2056/2056 [==============================] - 12s 6ms/sample - loss: 3.5303 - mae: 1.3412\n",
      "Epoch 38/50\n",
      "2056/2056 [==============================] - 21s 10ms/sample - loss: 3.8653 - mae: 1.4044\n",
      "Epoch 39/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 3.8811 - mae: 1.3215\n",
      "Epoch 40/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 3.4247 - mae: 1.3378\n",
      "Epoch 41/50\n",
      "2056/2056 [==============================] - 7s 4ms/sample - loss: 3.7714 - mae: 1.3695\n",
      "Epoch 42/50\n",
      "2056/2056 [==============================] - 11s 5ms/sample - loss: 3.1712 - mae: 1.2819\n",
      "Epoch 43/50\n",
      "2056/2056 [==============================] - 9s 4ms/sample - loss: 3.6502 - mae: 1.3360\n",
      "Epoch 44/50\n",
      "2056/2056 [==============================] - 7s 3ms/sample - loss: 3.2906 - mae: 1.3059\n",
      "Epoch 45/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 3.1979 - mae: 1.2761\n",
      "Epoch 46/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 3.8326 - mae: 1.3313\n",
      "Epoch 47/50\n",
      "2056/2056 [==============================] - 7s 4ms/sample - loss: 3.3368 - mae: 1.2880\n",
      "Epoch 48/50\n",
      "2056/2056 [==============================] - 7s 4ms/sample - loss: 3.2753 - mae: 1.2605\n",
      "Epoch 49/50\n",
      "2056/2056 [==============================] - 9s 4ms/sample - loss: 3.0817 - mae: 1.2730\n",
      "Epoch 50/50\n",
      "2056/2056 [==============================] - 8s 4ms/sample - loss: 3.0679 - mae: 1.2496\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe56112d080>"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "features_test = pd.DataFrame(features_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "res_mse, res_mae = my_model.evaluate(features_train_scaled, labels_train, verbose = 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(res_mse, res_mae)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2.560948381628044 1.1644819\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.6.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.13 64-bit ('tensorflow': conda)"
  },
  "interpreter": {
   "hash": "4ce6add6de03ec12ade4525d615de379e40b1ec772d0cb316a3e631e4469a5c4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}